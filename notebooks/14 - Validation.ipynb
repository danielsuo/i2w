{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673ed0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension horovod.torch has not been built: /opt/conda/lib/python3.7/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-37m-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import argparse\n",
    "import pathlib\n",
    "import os\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import flax\n",
    "from flax import jax_utils\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "import init2winit\n",
    "import fastmri\n",
    "\n",
    "import i2w\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "from fastmri.models import unet as t_unet\n",
    "from fastmri.pl_modules import data_module\n",
    "from fastmri.pl_modules import unet_module\n",
    "from fastmri.data.mri_data import SliceDataset\n",
    "from fastmri.data.transforms import *\n",
    "from fastmri.data.subsample import *\n",
    "\n",
    "from init2winit.model_lib import unet as f_unet\n",
    "from init2winit.dataset_lib import fastmri_dataset\n",
    "from init2winit.dataset_lib import data_utils\n",
    "from init2winit.optimizer_lib import optimizers\n",
    "from init2winit.optimizer_lib import transform\n",
    "from init2winit.model_lib import metrics\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3da1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbed from `train_unet_demo.build_args()`.\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    accelerations=[4],\n",
    "    accelerator='gpu',  # Should be `ddp`, but not available in interactive mode\n",
    "    accumulate_grad_batches=None,\n",
    "    amp_backend='native',\n",
    "    amp_level=None,\n",
    "    auto_lr_find=False,\n",
    "    auto_scale_batch_size=False,\n",
    "    auto_select_gpus=False,\n",
    "    batch_size=8,\n",
    "    benchmark=False,\n",
    "#     callbacks=[<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f409795e090>],\n",
    "    center_fractions=[0.08],\n",
    "    challenge='singlecoil',\n",
    "    chans=32,\n",
    "    check_val_every_n_epoch=1,\n",
    "    checkpoint_callback=None,\n",
    "    combine_train_val=False,\n",
    "    data_path=pathlib.PosixPath('/home/dsuo'),\n",
    "    default_root_dir=pathlib.PosixPath('unet/unet_demo'),\n",
    "    detect_anomaly=False, deterministic=True,\n",
    "    devices=None, drop_prob=0.0,\n",
    "    enable_checkpointing=True,\n",
    "    enable_model_summary=True,\n",
    "    enable_progress_bar=True,\n",
    "    fast_dev_run=False,\n",
    "    flush_logs_every_n_steps=None,\n",
    "    gpus=8,\n",
    "    gradient_clip_algorithm=None,\n",
    "    gradient_clip_val=None,\n",
    "    in_chans=1,\n",
    "    ipus=None,\n",
    "    limit_predict_batches=1.0,\n",
    "    limit_test_batches=1.0,\n",
    "    limit_train_batches=1.0,\n",
    "    limit_val_batches=1.0,\n",
    "    log_every_n_steps=50,\n",
    "    log_gpu_memory=None,\n",
    "    logger=True,\n",
    "    lr=0.001,\n",
    "    lr_gamma=0.1,\n",
    "    lr_step_size=40,\n",
    "    mask_type='random',  # Should be `random`, but tying out without\n",
    "    max_epochs=50,\n",
    "    max_steps=-1,\n",
    "    max_time=None,\n",
    "    min_epochs=None,\n",
    "    min_steps=None,\n",
    "    mode='train',\n",
    "    move_metrics_to_cpu=False,\n",
    "    multiple_trainloader_mode='max_size_cycle',\n",
    "    num_log_images=16,\n",
    "    num_nodes=1,\n",
    "    num_pool_layers=4,\n",
    "    num_processes=1,\n",
    "    num_sanity_val_steps=2,\n",
    "    num_workers=4,\n",
    "    out_chans=1,\n",
    "    overfit_batches=0.0,\n",
    "    plugins=None,\n",
    "    precision=32,\n",
    "    prepare_data_per_node=None,\n",
    "    process_position=0,\n",
    "    profiler=None,\n",
    "    progress_bar_refresh_rate=None,\n",
    "    reload_dataloaders_every_epoch=False,\n",
    "    reload_dataloaders_every_n_epochs=0,\n",
    "    replace_sampler_ddp=False,\n",
    "    resume_from_checkpoint=None,\n",
    "    sample_rate=None,\n",
    "    seed=42,\n",
    "    stochastic_weight_avg=False,\n",
    "    strategy='dp',  # This should be None\n",
    "    sync_batchnorm=False,\n",
    "    terminate_on_nan=None,\n",
    "    test_path=None,\n",
    "    test_sample_rate=None,\n",
    "    test_split='test',\n",
    "    test_volume_sample_rate=None,\n",
    "    tpu_cores=None,\n",
    "    track_grad_norm=-1,\n",
    "    use_dataset_cache_file=True,\n",
    "    val_check_interval=1.0,\n",
    "    val_sample_rate=None,\n",
    "    val_volume_sample_rate=None,\n",
    "    volume_sample_rate=None,\n",
    "    weight_decay=0.0,\n",
    "    weights_save_path=None,\n",
    "    weights_summary='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a7859a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(args.seed)\n",
    "\n",
    "# ------------\n",
    "# data\n",
    "# ------------\n",
    "# this creates a k-space mask for transforming input data\n",
    "mask = create_mask_for_mask_type(\n",
    "    args.mask_type, args.center_fractions, args.accelerations\n",
    ")\n",
    "\n",
    "mask = None\n",
    "\n",
    "# use random masks for train transform, fixed masks for val transform\n",
    "train_transform = UnetDataTransform(args.challenge, mask_func=mask, use_seed=False)\n",
    "val_transform = UnetDataTransform(args.challenge, mask_func=mask)\n",
    "test_transform = UnetDataTransform(args.challenge)\n",
    "# ptl data module - this handles data loaders\n",
    "dm = data_module.FastMriDataModule(\n",
    "    data_path=args.data_path,\n",
    "    challenge=args.challenge,\n",
    "    train_transform=train_transform,\n",
    "    val_transform=val_transform,\n",
    "    test_transform=test_transform,\n",
    "    test_split=args.test_split,\n",
    "    test_path=args.test_path,\n",
    "    sample_rate=args.sample_rate,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.num_workers,\n",
    "    distributed_sampler=(args.accelerator in (\"ddp\", \"ddp_cpu\")),\n",
    ")\n",
    "\n",
    "# ------------\n",
    "# model\n",
    "# ------------\n",
    "model = unet_module.UnetModule(\n",
    "    in_chans=args.in_chans,\n",
    "    out_chans=args.out_chans,\n",
    "    chans=args.chans,\n",
    "    num_pool_layers=args.num_pool_layers,\n",
    "    drop_prob=args.drop_prob,\n",
    "    lr=args.lr,\n",
    "    lr_step_size=args.lr_step_size,\n",
    "    lr_gamma=args.lr_gamma,\n",
    "    weight_decay=args.weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6cbf9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abs sum diff: 0.14279632\n"
     ]
    }
   ],
   "source": [
    "f_model = f_unet.UNetModel(f_unet.DEFAULT_HPARAMS, {}, 'mean_absolute_error', 'image_reconstruction_metrics')\n",
    "f_params = i2w.convert_params(model.cpu().unet, f_model.flax_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea161a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim = {}\n",
    "our_ssim = {}\n",
    "\n",
    "class cb(Callback):\n",
    "    def on_validation_batch_end(self, trainer, module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        ssim_vals = outputs['ssim_vals']\n",
    "        output = model(batch.image.cuda()).cpu()\n",
    "        mean = batch.mean.unsqueeze(1).unsqueeze(2)\n",
    "        std = batch.std.unsqueeze(1).unsqueeze(2)\n",
    "        output = output * std + mean\n",
    "        target = batch.target * std + mean\n",
    "        for image, target, max_value, file, slice_idx in zip(output, target, batch.max_value, batch.fname, batch.slice_num):\n",
    "            if file not in our_ssim:\n",
    "                our_ssim[file] = {}\n",
    "            our_ssim[file][slice_idx.detach().numpy().item()] = metrics.structural_similarity(image.detach().numpy(), target.detach().numpy(), max_value.detach().numpy().item())\n",
    "        for file in ssim_vals:\n",
    "            if file not in ssim:\n",
    "                ssim[file] = {}\n",
    "            for slice_idx in ssim_vals[file]:\n",
    "                ssim[file][slice_idx] = ssim_vals[file][slice_idx]\n",
    "                print(our_ssim[file][slice_idx], ssim[file][slice_idx])\n",
    "args.callbacks = [cb()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60a2eed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:464: UserWarning: more than one device specific flag has been set\n",
      "  rank_zero_warn(\"more than one device specific flag has been set\")\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer.from_argparse_args(args)\n",
    "trainer._data_connector.attach_data(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5952acf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b27aa548bdd485e9061fae04696fd77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6171981 tensor([0.6172], dtype=torch.float64)\n",
      "0.54074556 tensor([0.5407], dtype=torch.float64)\n",
      "0.48976827 tensor([0.4898], dtype=torch.float64)\n",
      "0.45737946 tensor([0.4574], dtype=torch.float64)\n",
      "0.45630378 tensor([0.4563], dtype=torch.float64)\n",
      "0.44610286 tensor([0.4461], dtype=torch.float64)\n",
      "0.432169 tensor([0.4322], dtype=torch.float64)\n",
      "0.39749438 tensor([0.3975], dtype=torch.float64)\n",
      "0.3542205 tensor([0.3542], dtype=torch.float64)\n",
      "0.29675758 tensor([0.2968], dtype=torch.float64)\n",
      "0.27975807 tensor([0.2798], dtype=torch.float64)\n",
      "0.27084792 tensor([0.2708], dtype=torch.float64)\n",
      "0.28663078 tensor([0.2866], dtype=torch.float64)\n",
      "0.28662282 tensor([0.2866], dtype=torch.float64)\n",
      "0.29736933 tensor([0.2974], dtype=torch.float64)\n",
      "0.30722082 tensor([0.3072], dtype=torch.float64)\n",
      "0.3196867 tensor([0.3197], dtype=torch.float64)\n",
      "0.33244863 tensor([0.3324], dtype=torch.float64)\n",
      "0.33592173 tensor([0.3359], dtype=torch.float64)\n",
      "0.33921346 tensor([0.3392], dtype=torch.float64)\n",
      "0.33476886 tensor([0.3348], dtype=torch.float64)\n",
      "0.3319372 tensor([0.3319], dtype=torch.float64)\n",
      "0.32614183 tensor([0.3261], dtype=torch.float64)\n",
      "0.30801448 tensor([0.3080], dtype=torch.float64)\n",
      "0.29201102 tensor([0.2920], dtype=torch.float64)\n",
      "0.29090157 tensor([0.2909], dtype=torch.float64)\n",
      "0.28613245 tensor([0.2861], dtype=torch.float64)\n",
      "0.28136522 tensor([0.2814], dtype=torch.float64)\n",
      "0.28670472 tensor([0.2867], dtype=torch.float64)\n",
      "0.2884819 tensor([0.2885], dtype=torch.float64)\n",
      "0.27155596 tensor([0.2716], dtype=torch.float64)\n",
      "0.2677765 tensor([0.2678], dtype=torch.float64)\n",
      "0.26350293 tensor([0.2635], dtype=torch.float64)\n",
      "0.24952674 tensor([0.2495], dtype=torch.float64)\n",
      "0.21301411 tensor([0.2130], dtype=torch.float64)\n",
      "0.3453802 tensor([0.3454], dtype=torch.float64)\n",
      "0.3399584 tensor([0.3400], dtype=torch.float64)\n",
      "0.33550078 tensor([0.3355], dtype=torch.float64)\n",
      "0.32818925 tensor([0.3282], dtype=torch.float64)\n",
      "0.32747388 tensor([0.3275], dtype=torch.float64)\n",
      "0.32235178 tensor([0.3224], dtype=torch.float64)\n",
      "0.3152318 tensor([0.3152], dtype=torch.float64)\n",
      "0.3097193 tensor([0.3097], dtype=torch.float64)\n",
      "0.30032134 tensor([0.3003], dtype=torch.float64)\n",
      "0.28245 tensor([0.2824], dtype=torch.float64)\n",
      "0.24885488 tensor([0.2489], dtype=torch.float64)\n",
      "0.24095823 tensor([0.2410], dtype=torch.float64)\n",
      "0.24950458 tensor([0.2495], dtype=torch.float64)\n",
      "0.25391787 tensor([0.2539], dtype=torch.float64)\n",
      "0.2618726 tensor([0.2619], dtype=torch.float64)\n",
      "0.26695278 tensor([0.2670], dtype=torch.float64)\n",
      "0.26788327 tensor([0.2679], dtype=torch.float64)\n",
      "0.2623491 tensor([0.2623], dtype=torch.float64)\n",
      "0.25464374 tensor([0.2546], dtype=torch.float64)\n",
      "0.25645342 tensor([0.2565], dtype=torch.float64)\n",
      "0.2517367 tensor([0.2517], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.validate(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5974a4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5535585 tensor([0.6172], dtype=torch.float64)\n",
      "0.5451602 tensor([0.5407], dtype=torch.float64)\n",
      "0.52114695 tensor([0.4898], dtype=torch.float64)\n",
      "0.49573553 tensor([0.4574], dtype=torch.float64)\n",
      "0.48832178 tensor([0.4563], dtype=torch.float64)\n",
      "0.47254547 tensor([0.4461], dtype=torch.float64)\n",
      "0.45443764 tensor([0.4322], dtype=torch.float64)\n",
      "0.41712266 tensor([0.3975], dtype=torch.float64)\n",
      "0.37166265 tensor([0.3542], dtype=torch.float64)\n",
      "0.3166698 tensor([0.2968], dtype=torch.float64)\n",
      "0.2916299 tensor([0.2798], dtype=torch.float64)\n",
      "0.28306213 tensor([0.2708], dtype=torch.float64)\n",
      "0.29582402 tensor([0.2866], dtype=torch.float64)\n",
      "0.29419816 tensor([0.2866], dtype=torch.float64)\n",
      "0.30037448 tensor([0.2974], dtype=torch.float64)\n",
      "0.3047076 tensor([0.3072], dtype=torch.float64)\n",
      "0.31222594 tensor([0.3197], dtype=torch.float64)\n",
      "0.32618305 tensor([0.3324], dtype=torch.float64)\n",
      "0.32425913 tensor([0.3359], dtype=torch.float64)\n",
      "0.3262578 tensor([0.3392], dtype=torch.float64)\n",
      "0.32289833 tensor([0.3348], dtype=torch.float64)\n",
      "0.32079688 tensor([0.3319], dtype=torch.float64)\n",
      "0.30763677 tensor([0.3261], dtype=torch.float64)\n",
      "0.29298338 tensor([0.3080], dtype=torch.float64)\n",
      "0.2730969 tensor([0.2920], dtype=torch.float64)\n",
      "0.2686552 tensor([0.2909], dtype=torch.float64)\n",
      "0.26370385 tensor([0.2861], dtype=torch.float64)\n",
      "0.2582946 tensor([0.2814], dtype=torch.float64)\n",
      "0.26883304 tensor([0.2867], dtype=torch.float64)\n",
      "0.27602163 tensor([0.2885], dtype=torch.float64)\n",
      "0.25983658 tensor([0.2716], dtype=torch.float64)\n",
      "0.26560098 tensor([0.2678], dtype=torch.float64)\n",
      "0.26155424 tensor([0.2635], dtype=torch.float64)\n",
      "0.2574642 tensor([0.2495], dtype=torch.float64)\n",
      "0.22617579 tensor([0.2130], dtype=torch.float64)\n",
      "0.260727 tensor([0.3454], dtype=torch.float64)\n",
      "0.25860023 tensor([0.3400], dtype=torch.float64)\n",
      "0.25655973 tensor([0.3355], dtype=torch.float64)\n",
      "0.25094423 tensor([0.3282], dtype=torch.float64)\n",
      "0.2535624 tensor([0.3275], dtype=torch.float64)\n",
      "0.2512877 tensor([0.3224], dtype=torch.float64)\n",
      "0.2492199 tensor([0.3152], dtype=torch.float64)\n",
      "0.24282211 tensor([0.3097], dtype=torch.float64)\n",
      "0.24112819 tensor([0.3003], dtype=torch.float64)\n",
      "0.22587694 tensor([0.2824], dtype=torch.float64)\n",
      "0.2037433 tensor([0.2489], dtype=torch.float64)\n",
      "0.19585243 tensor([0.2410], dtype=torch.float64)\n",
      "0.19989589 tensor([0.2495], dtype=torch.float64)\n",
      "0.20439124 tensor([0.2539], dtype=torch.float64)\n",
      "0.20768745 tensor([0.2619], dtype=torch.float64)\n",
      "0.20845394 tensor([0.2670], dtype=torch.float64)\n",
      "0.20528126 tensor([0.2679], dtype=torch.float64)\n",
      "0.20376825 tensor([0.2623], dtype=torch.float64)\n",
      "0.19469896 tensor([0.2546], dtype=torch.float64)\n",
      "0.1975664 tensor([0.2565], dtype=torch.float64)\n",
      "0.19218725 tensor([0.2517], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for file in ssim:\n",
    "    path = os.path.join('/home/dsuo/singlecoil_val', file)\n",
    "    for slice_idx in ssim[file]:\n",
    "        inputs = i2w.get_slice(path, slice_idx)\n",
    "        data = fastmri_dataset._process_example(*inputs, seed=tf.cast(jax.random.PRNGKey(0), tf.int64))\n",
    "        f_out = f_model.flax_module.apply(f_params, data['inputs'].numpy())\n",
    "        std = data['std'].numpy()\n",
    "        mean = data['mean'].numpy()\n",
    "        ss = metrics.structural_similarity(f_out * std + mean, data['targets'].numpy() * std + mean, inputs[-1])\n",
    "        print(ss, ssim[file][slice_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74447a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in ssim_vals:\n",
    "            path = os.path.join('/home/dsuo/singlecoil_val', file)\n",
    "            for slice_idx in ssim_vals[file]:\n",
    "                inputs = i2w.get_slice(path, slice_idx)\n",
    "                data = fastmri_dataset._process_example(*inputs, seed=tf.cast(jax.random.PRNGKey(0), tf.int64))\n",
    "                f_out = f_model.flax_module.apply(f_params, data['inputs'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
